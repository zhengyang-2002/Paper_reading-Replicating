{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29235588-5043-4b9f-9a51-fe490fc5b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76077246-9621-4b4a-add7-ffcbaa4ec0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1128c-024a-4054-9aaa-4dc57f058226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    embedding_size = 32\n",
    "    hidden_size = 128\n",
    "    vocab_size = 101\n",
    "    ouput_size = vocab_size\n",
    "    max_length = 15\n",
    "    \n",
    "    test_round = 1000\n",
    "    evaluate_round = 10\n",
    "\n",
    "    batch_size = 32\n",
    "    steps = int(15e3)\n",
    "    lr = 5e-4\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(f'device:{device}')\n",
    "\n",
    "    padding_value = 0\n",
    "    eos = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8af3277-4467-435d-827d-a62a11dc2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if is prime\n",
    "def is_prime(num):\n",
    "    if num < 2:\n",
    "        return False\n",
    "    for i in range(2, int(num**0.5) + 1):\n",
    "        if num % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# generate prime\n",
    "def generate_data(num_samples, max_length=cfg.max_length):\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for _ in range(num_samples):\n",
    "        # random generate\n",
    "        input_seq = [random.randint(0, cfg.vocab_size-2) for _ in range(random.randint(1, max_length))]\n",
    "        # build output\n",
    "        output_seq = [x for x in sorted([x for x in input_seq if is_prime(x)], reverse=True)]+[cfg.eos]\n",
    "        #data.append((\",\".join(map(str, input_seq)), \",\".join(output_seq)))\n",
    "        input_data.append(input_seq)\n",
    "        output_data.append(output_seq)\n",
    "    return input_data, output_data\n",
    "\n",
    "def generate_data(num_samples, reverse, max_length=cfg.max_length):\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for _ in range(num_samples):\n",
    "        # random generate\n",
    "        input_seq = [random.randint(1, 100) for _ in range(random.randint(1, max_length))]\n",
    "        # build target\n",
    "        output_seq = [x for x in input_seq if is_prime(x)] #[::-1]\n",
    "        output_seq.append(cfg.eos)\n",
    "        if reverse:\n",
    "            input_seq = input_seq[::-1]\n",
    "        else:\n",
    "            pass\n",
    "        input_data.append(input_seq)\n",
    "        output_data.append(output_seq)\n",
    "    return input_data, output_data\n",
    "\n",
    "\n",
    "# padding tensor to the max_length\n",
    "def list_2_tensor(data):\n",
    "    tensor_list = [torch.tensor(sublist, dtype=torch.long, device=cfg.device) for sublist in data]\n",
    "    padded_tensor = pad_sequence(tensor_list, batch_first=True, padding_value=cfg.padding_value)\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "class Seq_1(nn.Module):\n",
    "    '''\n",
    "    input are batchs of seqs, seqs have the undetermined length\n",
    "    output is the final hidden_state\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Seq_1, self).__init__()\n",
    "        #self.xh = nn.Linear(cfg.embedding_size, cfg.hidden_size)\n",
    "        self.xh = nn.Sequential(\n",
    "            nn.Linear(cfg.embedding_size, cfg.hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size//2, cfg.hidden_size)\n",
    "        )\n",
    "        #self.hh = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n",
    "        self.hh = nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size//2, cfg.hidden_size)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid is a class, inherit from nn.Module\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, seq, input_lengths):\n",
    "        batch_size, seq_len, embedding_size = seq.size()\n",
    "        mask = torch.arange(seq_len, device=cfg.device).expand(batch_size, -1) < input_lengths.unsqueeze(1) #shape become [batch_size, 1] '1' can be used in any compare, no matter the shape of another tensor (auto broadcast)\n",
    "\n",
    "        # hidden state should correspond to the batch_size, is not the parameter, is more like the temperate variable\n",
    "        hidden_state = torch.zeros(batch_size, cfg.hidden_size, device=cfg.device) # needn't expand into two dim, we can just simply broadcast it\n",
    "        #hidden_state = torch.zeros(cfg.hidden_size, device=cfg.device)\n",
    "        #tokens = torch.unbind(seq, dim=1) # unbind the seq form the dim 1\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            token = seq[:,t,:] # unbind from the dim of tokens\n",
    "            current_mask = mask[:, t].unsqueeze(1)\n",
    "            #temp_hidden_state = self.sigmoid(self.xh(token)+self.hh(hidden_state))\n",
    "            temp_hidden_state = self.tanh(self.xh(token)+self.hh(hidden_state))\n",
    "            hidden_state = torch.where(current_mask, temp_hidden_state, hidden_state)\n",
    "    \n",
    "        return hidden_state\n",
    "\n",
    "class Seq_2(nn.Module):\n",
    "    '''\n",
    "    input: hidden state from seq_1\n",
    "    output result tokens\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Seq_2, self).__init__()\n",
    "        self.hh = nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size//2, cfg.hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hv = nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size//2, cfg.vocab_size)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid is a class, inherit from nn.Module\n",
    "\n",
    "    def forward(self, hidden_state, decode_length):\n",
    "        batch_size, _ = hidden_state.size()\n",
    "        outputs = torch.zeros(batch_size, decode_length, cfg.vocab_size, device=cfg.device) # this tensor have a continual ram space, use it to avoid using torch.cat(), which cause O(n^2) complexity\n",
    "        \n",
    "        for t in range(decode_length):\n",
    "            hidden_state = self.hh(hidden_state)\n",
    "            outputs[:,t,:] = self.hv(hidden_state) # just output logits, loss function will handle softmax\n",
    "    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352c1ac6-8a16-49ef-8398-8b9e11187854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_length(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if a[i - 1] == b[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "    return dp[m][n]\n",
    "\n",
    "def calculate_metrics(target, pred, pad_token=100):\n",
    "    # get the legal length\n",
    "    target_valid_len = target.index(pad_token) if pad_token in target else len(target)\n",
    "    target_valid = target[:target_valid_len]\n",
    "    \n",
    "    # get the legal length \n",
    "    if pad_token in pred:\n",
    "        pred_valid_len = pred.index(pad_token)\n",
    "        pred_valid = pred[:pred_valid_len]\n",
    "    else:\n",
    "        pred_valid_len = len(pred)\n",
    "        pred_valid = pred.copy()\n",
    "    \n",
    "    aligned_pred = []\n",
    "    for i in range(target_valid_len):\n",
    "        if i < len(pred_valid):\n",
    "            aligned_pred.append(pred_valid[i])\n",
    "        else:\n",
    "            aligned_pred.append(pad_token)  # 填充\n",
    "\n",
    "    match_count = sum(1 for t, p in zip(target_valid, aligned_pred) if t == p)\n",
    "    psa = match_count / target_valid_len if target_valid_len > 0 else 0.0\n",
    "\n",
    "    lcs = lcs_length(target_valid, aligned_pred)\n",
    "    lcsr = lcs / target_valid_len if target_valid_len > 0 else 0.0\n",
    "\n",
    "    geo_mean = (psa * lcsr) ** 0.5 if psa > 0 and lcsr > 0 else 0.0\n",
    "    \n",
    "    return psa, lcsr, geo_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a4068-bda3-4e22-bce2-9f98fe9e769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(reverse):\n",
    "    seq_1 = Seq_1().to(cfg.device)\n",
    "    seq_2 = Seq_2().to(cfg.device)\n",
    "    embedding = nn.Embedding(cfg.vocab_size, cfg.embedding_size, device=cfg.device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(\n",
    "        list(seq_1.parameters()) + list(seq_2.parameters()) + list(embedding.parameters()),\n",
    "        lr=cfg.lr\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "\n",
    "    seq_1.train()\n",
    "    seq_2.train()\n",
    "    embedding.train()\n",
    "    \n",
    "    for step in tqdm.trange(cfg.steps, desc=\"Training\"):\n",
    "        data = generate_data(cfg.batch_size, reverse)\n",
    "        input_lengths = torch.tensor([len(seq) for seq in data[0]], device=cfg.device)\n",
    "        batch_input = list_2_tensor(data[0])\n",
    "        batch_target = list_2_tensor(data[1])\n",
    "        \n",
    "        embedded = embedding(batch_input)\n",
    "        hidden = seq_1(embedded, input_lengths)\n",
    "        outputs = seq_2(hidden, batch_target.size(1))\n",
    "        \n",
    "        loss = criterion(outputs.view(-1, cfg.vocab_size), batch_target.view(-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    seq_1.eval()\n",
    "    seq_2.eval()\n",
    "    embedding.eval()\n",
    "    \n",
    "    total_psa, total_lcsr, total_geo, num_samples = 0.0, 0.0, 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(cfg.test_round):\n",
    "            data = generate_data(cfg.batch_size, reverse)\n",
    "            batch_input = list_2_tensor(data[0])\n",
    "            batch_target = list_2_tensor(data[1])\n",
    "\n",
    "            embedded = embedding(batch_input)\n",
    "            hidden = seq_1(embedded, torch.tensor([len(seq) for seq in data[0]], device=cfg.device))\n",
    "            outputs = seq_2(hidden, batch_target.size(1))\n",
    "            preds = outputs.argmax(-1).cpu().tolist()\n",
    "\n",
    "            for idx in range(cfg.batch_size):\n",
    "                target_seq = data[1][idx]\n",
    "                pred_seq = preds[idx]\n",
    "                \n",
    "                psa, lcsr, geo = calculate_metrics(target_seq, pred_seq)\n",
    "                total_psa += psa\n",
    "                total_lcsr += lcsr\n",
    "                total_geo += geo\n",
    "                num_samples += 1\n",
    "\n",
    "    return (\n",
    "        total_psa / num_samples,\n",
    "        total_lcsr / num_samples,\n",
    "        total_geo / num_samples\n",
    "    )\n",
    "\n",
    "def main(reverse):\n",
    "    all_psa, all_lcsr, all_geo = [], [], []\n",
    "    \n",
    "    for round in range(cfg.evaluate_round):\n",
    "        print(f\"------ Round {round+1}/{cfg.evaluate_round} ------\")\n",
    "        psa, lcsr, geo = train_and_evaluate(reverse)\n",
    "        \n",
    "        all_psa.append(psa)\n",
    "        all_lcsr.append(lcsr)\n",
    "        all_geo.append(geo)\n",
    "        \n",
    "        print(f\"[Round {round+1}] PSA: {psa:.4f}, LCSR: {lcsr:.4f}, GeoMean: {geo:.4f}\")\n",
    "\n",
    "    final_psa = sum(all_psa) / len(all_psa)\n",
    "    final_lcsr = sum(all_lcsr) / len(all_lcsr)\n",
    "    final_geo = sum(all_geo) / len(all_geo)\n",
    "    \n",
    "    print(\"\\n=== Final Average Metrics ===\")\n",
    "    print(f\"PSA: {final_psa:.4f}\")\n",
    "    print(f\"LCSR: {final_lcsr:.4f}\")\n",
    "    print(f\"GeoMean: {final_geo:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1c62c4-8442-424d-aaaf-e5a06dc39b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Round 1/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] PSA: 0.0476, LCSR: 0.0622, GeoMean: 0.0482\n",
      "------ Round 2/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:50<00:00, 135.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 2] PSA: 0.2761, LCSR: 0.3000, GeoMean: 0.2785\n",
      "------ Round 3/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 3] PSA: 0.0321, LCSR: 0.0655, GeoMean: 0.0327\n",
      "------ Round 4/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:52<00:00, 132.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 4] PSA: 0.3231, LCSR: 0.3438, GeoMean: 0.3263\n",
      "------ Round 5/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 5] PSA: 0.0316, LCSR: 0.0635, GeoMean: 0.0323\n",
      "------ Round 6/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 133.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 6] PSA: 0.0809, LCSR: 0.1041, GeoMean: 0.0814\n",
      "------ Round 7/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 7] PSA: 0.0326, LCSR: 0.0705, GeoMean: 0.0334\n",
      "------ Round 8/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 8] PSA: 0.2516, LCSR: 0.2715, GeoMean: 0.2533\n",
      "------ Round 9/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 9] PSA: 0.2158, LCSR: 0.2363, GeoMean: 0.2174\n",
      "------ Round 10/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 10] PSA: 0.2154, LCSR: 0.2414, GeoMean: 0.2169\n",
      "\n",
      "=== Final Average Metrics ===\n",
      "PSA: 0.1507\n",
      "LCSR: 0.1759\n",
      "GeoMean: 0.1520\n"
     ]
    }
   ],
   "source": [
    "main(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51466dc5-3419-4d0b-839f-8e5fb84708c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Round 1/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 133.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] PSA: 0.1646, LCSR: 0.1862, GeoMean: 0.1653\n",
      "------ Round 2/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:54<00:00, 130.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 2] PSA: 0.0701, LCSR: 0.0924, GeoMean: 0.0705\n",
      "------ Round 3/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 3] PSA: 0.2036, LCSR: 0.2250, GeoMean: 0.2044\n",
      "------ Round 4/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:52<00:00, 133.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 4] PSA: 0.1281, LCSR: 0.1516, GeoMean: 0.1288\n",
      "------ Round 5/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:55<00:00, 129.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 5] PSA: 0.0322, LCSR: 0.0646, GeoMean: 0.0326\n",
      "------ Round 6/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:52<00:00, 133.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 6] PSA: 0.0478, LCSR: 0.0733, GeoMean: 0.0483\n",
      "------ Round 7/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 7] PSA: 0.0331, LCSR: 0.0657, GeoMean: 0.0337\n",
      "------ Round 8/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 8] PSA: 0.1777, LCSR: 0.2027, GeoMean: 0.1785\n",
      "------ Round 9/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 9] PSA: 0.1898, LCSR: 0.2135, GeoMean: 0.1908\n",
      "------ Round 10/10 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████| 15000/15000 [01:51<00:00, 134.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 10] PSA: 0.0368, LCSR: 0.0639, GeoMean: 0.0374\n",
      "\n",
      "=== Final Average Metrics ===\n",
      "PSA: 0.1084\n",
      "LCSR: 0.1339\n",
      "GeoMean: 0.1090\n"
     ]
    }
   ],
   "source": [
    "main(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
