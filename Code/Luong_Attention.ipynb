{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76077246-9621-4b4a-add7-ffcbaa4ec0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import math\n",
    "import tools\n",
    "import Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bcaad4-a15b-47c2-91c4-ebe1e58c328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Luong_AttentionTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.encoder = self.config.encoder(self.config).to(self.config.device)\n",
    "        self.decoder = self.config.decoder(self.config).to(self.config.device)\n",
    "        self.embedding = nn.Embedding(self.config.vocab_size, self.config.embedding_size, device=self.config.device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.config.padding_value)\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.encoder.parameters()) +\n",
    "            list(self.decoder.parameters()) +\n",
    "            list(self.embedding.parameters()),\n",
    "            lr=self.config.lr\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=5000, gamma=0.1)\n",
    "        \n",
    "    @staticmethod\n",
    "    def is_prime(num):\n",
    "        if num < 2:\n",
    "            return False\n",
    "        for i in range(2, int(num**0.5) + 1):\n",
    "            if num % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def generate_data(self, num_samples, reverse):\n",
    "        input_data = []\n",
    "        output_data = []\n",
    "        for _ in range(num_samples):\n",
    "            input_seq = [random.randint(1, 100) for _ in range(random.randint(1, self.config.max_length))]\n",
    "            output_seq = [x for x in input_seq if self.is_prime(x)]\n",
    "            output_seq.append(self.config.eos)\n",
    "            if reverse:\n",
    "                input_seq = input_seq[::-1]\n",
    "            input_data.append(input_seq)\n",
    "            output_data.append(output_seq)\n",
    "        return input_data, output_data\n",
    "    \n",
    "    def list_2_tensor(self, data):\n",
    "        tensor_list = [torch.tensor(sublist, dtype=torch.long, device=self.config.device) for sublist in data]\n",
    "        padded_tensor = pad_sequence(tensor_list, batch_first=True, padding_value=self.config.padding_value)\n",
    "        return padded_tensor\n",
    "    \n",
    "    @staticmethod\n",
    "    def lcs_length(a, b):\n",
    "        m, n = len(a), len(b)\n",
    "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if a[i - 1] == b[j - 1]:\n",
    "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "        return dp[m][n]\n",
    "    \n",
    "    def calculate_metrics(self, target, pred):\n",
    "        pad_token = self.config.eos\n",
    "        target_valid_len = target.index(pad_token) if pad_token in target else len(target)\n",
    "        target_valid = target[:target_valid_len]\n",
    "        \n",
    "        if pad_token in pred:\n",
    "            pred_valid_len = pred.index(pad_token)\n",
    "            pred_valid = pred[:pred_valid_len]\n",
    "        else:\n",
    "            pred_valid_len = len(pred)\n",
    "            pred_valid = pred.copy()\n",
    "        \n",
    "        aligned_pred = []\n",
    "        for i in range(target_valid_len):\n",
    "            if i < len(pred_valid):\n",
    "                aligned_pred.append(pred_valid[i])\n",
    "            else:\n",
    "                aligned_pred.append(pad_token)\n",
    "\n",
    "        match_count = sum(1 for t, p in zip(target_valid, aligned_pred) if t == p)\n",
    "        psa = match_count / target_valid_len if target_valid_len > 0 else 0.0\n",
    "\n",
    "        lcs = self.lcs_length(target_valid, aligned_pred)\n",
    "        lcsr = lcs / target_valid_len if target_valid_len > 0 else 0.0\n",
    "\n",
    "        geo_mean = (psa * lcsr) ** 0.5 if psa > 0 and lcsr > 0 else 0.0\n",
    "        \n",
    "        return psa, lcsr, geo_mean\n",
    "    \n",
    "    def train(self, reverse=True):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        self.embedding.train()\n",
    "        \n",
    "        for step in tqdm.trange(self.config.steps, desc=\"Training\"):\n",
    "            data = self.generate_data(self.config.batch_size, reverse)\n",
    "            input_lengths = torch.tensor([len(seq) for seq in data[0]], device=self.config.device)\n",
    "            batch_input = self.list_2_tensor(data[0])\n",
    "            batch_target = self.list_2_tensor(data[1])\n",
    "            \n",
    "            embedded = self.embedding(batch_input)\n",
    "            hidden_state_records = self.encoder(embedded, input_lengths)\n",
    "            outputs = self.decoder(hidden_state_records, batch_target.size(1))\n",
    "            \n",
    "            loss = self.criterion(outputs.view(-1, self.config.vocab_size), batch_target.view(-1))\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "    \n",
    "    \n",
    "    def evaluate(self, reverse=True):\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        self.embedding.eval()\n",
    "        \n",
    "        total_psa, total_lcsr, total_geo, num_samples = 0.0, 0.0, 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(self.config.test_round):\n",
    "                data = self.generate_data(self.config.batch_size, reverse)\n",
    "                input_lengths = torch.tensor([len(seq) for seq in data[0]], device=self.config.device)\n",
    "                batch_input = self.list_2_tensor(data[0])\n",
    "                batch_target = self.list_2_tensor(data[1])\n",
    "                \n",
    "                embedded = self.embedding(batch_input)\n",
    "                hidden_state_records = self.encoder(embedded, input_lengths)\n",
    "                outputs = self.decoder(hidden_state_records, batch_target.size(1))\n",
    "                \n",
    "                preds = outputs.argmax(-1).cpu().tolist()\n",
    "    \n",
    "                for idx in range(self.config.batch_size):\n",
    "                    target_seq = data[1][idx]\n",
    "                    pred_seq = preds[idx]\n",
    "                    \n",
    "                    psa, lcsr, geo = self.calculate_metrics(target_seq, pred_seq)\n",
    "                    total_psa += psa\n",
    "                    total_lcsr += lcsr\n",
    "                    total_geo += geo\n",
    "                    num_samples += 1\n",
    "    \n",
    "        return (\n",
    "            total_psa / num_samples,\n",
    "            total_lcsr / num_samples,\n",
    "            total_geo / num_samples\n",
    "        )\n",
    "    \n",
    "    def train_and_evaluate(self, reverse=True, num_rounds=None):\n",
    "        if num_rounds is None:\n",
    "            num_rounds = self.config.evaluate_round\n",
    "            \n",
    "        all_psa, all_lcsr, all_geo = [], [], []\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            print(f\"------ Round {round+1}/{num_rounds} ------\")\n",
    "            self._init_model()\n",
    "            self.train(reverse)\n",
    "            psa, lcsr, geo = self.evaluate(reverse)\n",
    "            \n",
    "            all_psa.append(psa)\n",
    "            all_lcsr.append(lcsr)\n",
    "            all_geo.append(geo)\n",
    "            \n",
    "            print(f\"[Round {round+1}] PSA: {psa:.4f}, LCSR: {lcsr:.4f}, GeoMean: {geo:.4f}\")\n",
    "\n",
    "        final_psa = sum(all_psa) / len(all_psa)\n",
    "        final_lcsr = sum(all_lcsr) / len(all_lcsr)\n",
    "        final_geo = sum(all_geo) / len(all_geo)\n",
    "        \n",
    "        print(\"\\n=== Final Average Metrics ===\")\n",
    "        print(f\"PSA: {final_psa:.4f}\")\n",
    "        print(f\"LCSR: {final_lcsr:.4f}\")\n",
    "        print(f\"GeoMean: {final_geo:.4f}\")\n",
    "        \n",
    "        return final_psa, final_lcsr, final_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bde6a7-6191-4e36-8db4-68b6c59d2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    def __init__(self, \n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 embedding_size=32,\n",
    "                 hidden_size=128,\n",
    "                 vocab_size=101,\n",
    "                 max_length=10,\n",
    "                 evaluate_round=3,\n",
    "                 batch_size=32,\n",
    "                 steps=5000,\n",
    "                 lr=5e-4,\n",
    "                 device=None,\n",
    "                 padding_value=0,\n",
    "                 eos=100\n",
    "                ):\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.test_round = steps//10\n",
    "        self.evaluate_round = evaluate_round\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        self.lr = lr\n",
    "        self.padding_value = padding_value\n",
    "        self.eos = eos\n",
    "        \n",
    "        # 自动检测设备\n",
    "        if device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.device = 'cpu'\n",
    "\n",
    "    def params(self):\n",
    "        return{\n",
    "            'encoder.name': self.encoder.name,\n",
    "            'decoder.name': self.decoder.name,\n",
    "            'embedding_size': self.embedding_size,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'output_size': self.output_size,\n",
    "            'max_length': self.max_length,\n",
    "            'test_round': self.test_round,\n",
    "            'evaluate_round': self.evaluate_round,\n",
    "            'batch_size': self.batch_size,\n",
    "            'steps': self.steps,\n",
    "            'lr': self.lr,\n",
    "            'padding_value': self.padding_value,\n",
    "            'eos': self.eos,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ca9b0-5487-4a04-a0db-313b41f12c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [Model.Luong_Encoder]\n",
    "decoders = [Model.Luong_Decoder_Dot] #[Model.Attention_Decoder, Model.Attention_Decoder_41, Model.Attention_Decoder_42, Model.Attention_Decoder_43]\n",
    "max_lengths = [i*50+10 for i in range(7)]\n",
    "\n",
    "config_params = [{'encoder': encoder, 'decoder': decoder, 'max_length': max_length} for encoder in encoders for decoder in decoders for max_length in max_lengths]\n",
    "\n",
    "result = []\n",
    "for config_param in config_params:\n",
    "    train_config = TrainingConfig(**config_param)\n",
    "    print(train_config.params())\n",
    "    trainer = Luong_AttentionTrainer(train_config)\n",
    "    final_psa, final_lcsr, final_geo = trainer.train_and_evaluate(reverse=True)\n",
    "    result.append((train_config.params(), {'final_psa': final_psa, 'final_lcsr': final_lcsr, 'final_geo': final_geo}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
